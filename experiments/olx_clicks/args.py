"""Created at 11/04/2019@author: dimitris.michailidis"""from helpers.enums import CombinationMode, ParallelMode, LocationMode, LatentModeclass Args:    def __init__(self):        # self.data_folder = 'data/olx_train/clicks/item_freq_10'        # self.data_folder = 'data/olx_train/clicks/vehicles/'        self.data_folder = 'data/olx_train/clicks/samples/'        # self.data_folder = 'data/test/'        self.train_path = 'train.csv'        self.valid_path = 'test.csv'        self.test_path = 'test.csv'        # The folder in which to save a model's instance after each epoch's.        self.checkpoint_dir = 'checkpoint'        # If true, it will load the model from 'pretrained_model_loc' and evaluate it on the test set.        self.evaluate = False        self.use_cuda = False        self.pretrained_model_loc = ''        # the k in recall@k, mrr@k - not really relevant, the scripts currently return 5,10,20        self.topk = 20        # More info under /helpers/enums.py        # NONE, DISTHOT, FULLCONCAT, CITYHOT, DISTRICTHOT, CONCAT, DISTANCE        self.location_mode = LocationMode.FULLCONCAT        # NONE, ENCODER, DECODER, HIDDEN        self.parallel_mode = ParallelMode.NONE        # NONE, LATENTAPPEND, LATENTEMBEDD, LATENTMULTIPLY, LATENTCONCAT        self.latent_mode = LatentMode.NONE        # CONCAT, MULTIPLY, ADD, WEIGHTED_SUM        self.combination_mode = CombinationMode.WEIGHTED_SUM        self.hidden_size = 100        self.num_layers = 1        self.batch_size = 10        self.dropout_input = 0        self.dropout_hidden = 0        self.optimizer_type = 'Adagrad'        # activation that returns the final rankings        self.final_act = 'tanh'        # learning rate        self.lr = 0.05        self.weight_decay = 0        self.momentum = 0        self.eps = 1e-6        # random seed        self.seed = 7        self.sigma = None        # embedding size dimention for the event and the location in latent mode        self.embedding_dim = 100        self.loss_type = 'TOP1-max'        self.n_epochs = 5        self.time_sort = False        self.model_name = 'GRU4REC'        # number of extra negative samples to sample from the dataset        self.n_sample = 0        # hyperparameter for sample. 1 = popularity based sampling, 0 = uniform sampling.        self.sample_alpha = 0        # the number of weights learned from the location context in latent context mode        self.context_size = 32